# Apache Flume
-- Apache Flume is a distributed, reliable system for effectively collecting, aggregating and moving large amounts of log data from different sources to a centralized datastore. The use of Apache Flume is not only restricted to log aggregation. 
Since Apache Flume sources are customizable. Flume can be used to transport massive quantities of event data including but not limited to network traffic data, social-media-generated data, email messages and pretty much any data source possible.

-- What is a Flume Agent ? And what is the data flow model of Flume ?
-- A Flume Agent is a JVM process that hosts the components like source, channel and sink through which the events flow.
-- In Flume each and every data is called Event.

#Important components in Flume
--Source
A Flume Source consumes events delivered to it by an external source like a webserver. The external source sends events to Flume in a format that is recognized by the target Flume source.
For example, an Avro Flume source can be used to receive Avro events from Avro clients.
--Channel
The channel is a passive store that keeps the event until it’s consumed by a Flume sink.
-- Sink
The sink removes the event from the channel and puts it into an external repository like HDFS(via Flume HDFS Sink) or or forwards it to the Flume source of the next Flume agent (next hop) in the flow.

#Setting up an agent.
Flume agent configuration is stored in a local configuration file(follows Java properties file format).
Configurations for more than one agent also can be specified in a single configuration file.
The configuration file inlcudes properties of source, channel and sink in an agent and how they are wired together to form data flows.

#Configuring individual components
Each component (source, sink or channel) in the flow has a name, type, and set of properties that are specific to the type and instantiation. For example, an Avro source needs a hostname (or IP address) and a port number to receive data from. A memory channel can have max queue size (“capacity”), and an HDFS sink needs to know the file system URI, path to create files, frequency of file rotation (“hdfs.rollInterval”) etc. All such attributes of a component needs to be set in the properties file of the hosting Flume agent.

#Wiring the pieces together
The agent needs to know what individual components to load and how they are connected in order to constitute the flow. This is done by listing the names of each of the sources, sinks and channels in the agent, and then specifying the connecting channel for each sink and source. For example, an agent flows events from an Avro source called avroWeb to HDFS sink hdfs-cluster1 via a file channel called file-channel. The configuration file will contain names of these components and file-channel as a shared channel for both avroWeb source and hdfs-cluster1 sink.
-- Example:
# Bind the source and sink to the channel
a1.sources.r1.channels = c1
a1.sinks.k1.channel = c1
